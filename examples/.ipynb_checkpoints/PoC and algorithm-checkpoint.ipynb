{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/rdf_data_citation')\n",
    "sys.path.insert(0, '../Playground')\n",
    "\n",
    "import rdf_data_citation\n",
    "\n",
    "from citation_utils import CitationData\n",
    "import rdf_star\n",
    "from rdf_star import TripleStoreEngine\n",
    "from citation_utils import QueryData, RDFDataSetData, CitationData\n",
    "from citation_utils import generate_citation_snippet, _intersection, _citation_timestamp_format\n",
    "import query_store as qs\n",
    "import queries_for_testing as q\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import pandas as pd\n",
    "from rdflib.term import Variable\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data and query store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R1 - Data Versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming from relational databases a triple store can be imagined as a table with three fields - subject, predicate, object. if one were about to annotate a triple with a timestamp or other label the fact that no additional “column” can be used within a triple store but only additional rows would make it hard to reference a specific triple. All that could be done is to insert another triple to somehow reference the target triple. However, where would this new triple point at or what would be the subject? Figure 1 illustrates this problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='figures/figure 1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can easily see the problem that the placeholder ? can only take one piece of information (subject or object) of the target triple which does not suffice to reference the triple as a whole. However, if one were able to nest a whole triple within the subject of another it would endow us with the right tool to address data versioning within triple stores. In fact, RDF* and SPARQL* as extensions of RDF and SPARQL respectively are capable of doing exactly this. Figure 2 illustrates the solution for the example brought in figure 1 in actual RDF* syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='figures/figure 2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This capability of nesting triples is only part of the solution. However, now we can use existing methods that also can be used within relational databases. One way is to use a start and an end date for each triple. As an initial operation all triples should be annotated with the current timestamp as the start date and an end date that is far in the future, e.g. 9999-12-31T00:00.000. From here we have to distinguish between insert, update and delete operations. Finally, to retrieve data as it existed at a certain point in time we would use simple filter operations on the start date and end date attributes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever a new triple is inserted two additional triples will be inserted - one marking the start date (e.g. current timestamp) of that triple and one setting the end date to 9999-12-31T00:00.000 to mark it as valid until further notice. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='figures/figure 3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update operation is a combination of a delete operation followed by an insert. We first must make clear what is actually updated. Here it again helps to think in terms of relational databases. The subject can be seen as a table, the predicate as an attribute of that table and the object as a particular value of that attribute. As we are updating data it goes without saying that we want to perform these operations on the object (the value) of the triple. Therefore, we first perform a delete on the end date of the target triple. Subsequently, we want to give a new end date to the target triple and this could be the current timestamp as this operation is performed. So far, we have only outdated the old value. What is now left to do is to basically perform the same operation as in Insert chapter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='figures/figure 4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea for the delete operation has already been conceived in the first part of the update operation. Firstly, the target triple’s end date is deleted and secondly the target triple is provided with a new end date, e.g. as of operation date. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='figures/figure 7.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof of concept\n",
    "Following example shall demonstrate that with the above discussed solution it is possible to retrieve earlier states of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up endpoints\n",
    "rdf_engine = TripleStoreEngine('http://192.168.0.241:7200/repositories/DataCitation', #GET\n",
    "                               'http://192.168.0.241:7200/repositories/DataCitation/statements') #POST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query and prefixes must be separated to make it easier to only nest the query within\n",
    "the SPARL template for timestamping (See R7 below) queries while the prefixes will go on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test query and timestamps\n",
    "prefixes = {'citing': 'http://ontology.ontotext.com/citing/',\n",
    "            'pub': 'http://ontology.ontotext.com/taxonomy/',\n",
    "            'xsd': 'http://www.w3.org/2001/XMLSchema#',\n",
    "            'publishing': 'http://ontology.ontotext.com/publishing#'}\n",
    "\n",
    "original_query = \"\"\"\n",
    "select ?mention ?party ?person ?document ?personLabel ?value {\n",
    "    ?mention publishing:hasInstance ?person .\n",
    "    ?document publishing:containsMention ?mention . \n",
    "    ?person pub:memberOfPoliticalParty ?party .\n",
    "    ?person pub:preferredLabel ?personLabel .\n",
    "    ?party pub:hasValue ?value .\n",
    "    ?value pub:preferredLabel \"Democratic Party\"@en .\n",
    "    filter(?personLabel = \"Judy Chu\"@en)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "vieTZObject = timezone(timedelta(hours=2))\n",
    "timestamp1 = datetime(2020, 9, 8, 12, 11, 21, 941000, vieTZObject)\n",
    "timestamp2 = datetime(2020, 10, 4, 18, 11, 21, 941000, vieTZObject)\n",
    "timestamp3 = datetime(2020, 10, 5, 18, 11, 21, 941000, vieTZObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "queryUtils = QueryData(original_query, timestamp1, prefixes)\n",
    "timestamped_query_1 = queryUtils.decorate_query()\n",
    "rdf_engine.get_data(timestamped_query_1, prefixes) # dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp 2 > timestamp 1\n",
    "timestamped_query_2 = queryUtils.decorate_query(citation_timestamp=timestamp2)\n",
    "rdf_engine.get_data(timestamped_query_2, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp 3 > timestamp 2\n",
    "timestamped_query_3 = queryUtils.decorate_query(citation_timestamp=timestamp3)\n",
    "rdf_engine.get_data(timestamped_query_3, prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now assume that new triples get added to the tripple store which affect the original query. While the original query will return a different result the timestamped query will always yield the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention = \"<hhttp://data.ontotext.com/publishing#Mention-dbaa4de4563be5f6b927c87e09f90461c09451296f4b52b1f80dcb6e941a5acd>\"\n",
    "hasInstance = \"publishing:hasInstance\"\n",
    "person = \"<http://ontology.ontotext.com/resource/tsm835hi3s3k>\"\n",
    "\n",
    "rdf_engine.insert_triple((mention, hasInstance, person), prefixes)\n",
    "\n",
    "document = \"<http://www.reuters.com/article/2014/10/10/us-usa-california-mountains-idUSKCN0HZ0U720141010>\"\n",
    "containsMention = \"publishing:containsMention\"\n",
    "mention = \"<hhttp://data.ontotext.com/publishing#Mention-dbaa4de4563be5f6b927c87e09f90461c09451296f4b52b1f80dcb6e941a5acd>\"\n",
    "\n",
    "rdf_engine.insert_triple((document, containsMention, mention), prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No change for timestamped query\n",
    "rdf_engine.get_data(timestamped_query_3, prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the timestamped dateset, as before, yields no rows, as all rows concerning this subset have been deleted between timestamp2 and timestamp3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original query also returns the newly added row now\n",
    "rdf_engine.get_data(original_query, prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the actual dataset has been modified with our insert statement above and therefore returns a row. Not all the triples from the original query needed to be inserted but only the ones that made the join find no matches anymore after they have been deleted. Therefore it suffices to only \"back insert\" the triples that have previously been deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_engine._delete_triples((mention, hasInstance, person), prefixes)\n",
    "rdf_engine._delete_triples((document, containsMention, mention), prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last piece of code just makes sure to delete the previously added triples and their annotations to make this demonstration re-executable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 - Timestamping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations on data should be timestamped. If we look at the suggested solution for R1, we see that timestamps are already applied with every operation. Now, one could use the operation timestamp for both - versioning data and timestamping the operation itself. The proposed solution for R1 would allow retrieving each operation’s timestamp but also a specific version of the dataset (as it was at a specific point in time). The start date annotation tells us also the timestamp of the insert and update operation. If a semantically valid end date (not 9999-12-31T00:00.000) is used to mark triples as outdated it can also be seen as the timestamp of the delete operation. \n",
    "However, if one wants to distinguish between a real delete and a delete as part of an update, this approach would lead to ambiguity. Therefore, another proposed solution is to use a further annotation “operation_date” and stamp the operation itself. This solution has the following benefit: A different timestamp than the operation timestamp could be used for versioning data. Some use cases might require to version data with specific timestamps (E.g. end of the day the operation was performed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R3 - Query Store Facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query store is a means to store queries and the associated metadata. For the query store it is not important whether the underlying database is a graph database, document-based or relational database. The query itself is just a string of characters in all cases and a simple database like SQLite in combination with Python’s object relational mapper SQL Alchemy is proposed as the Query Store. An examination of query store implementations by EODC, VMC, CCCA, EHR and VAMDC exposed following more common metadata which are proposed to by covered by default by the framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='figures/figure 6.png', width=800, height=680)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistently Identify Specific Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='figures/figure 5.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time a data set should be persisted the following operations are performed. The algorithm starts of with two parallel and independent streams of operations. Thus, in the implementation it does not matter which one gets executed first. The **left stream** ultimately searches the query store for the provided query. It does so by trying to find a matching query checksum of the normalized query. Therefore, normalization and query checksum compuation comes before the lookup. The **right stream** sets the ground for comparison of the result set checksums once the query has been found in the query store. Before the result set checksum compuation the query must be extended with a timestamp filter and sort operation. \n",
    "\n",
    "Next, a few case distinctions are needed. If the **query is found** we compare the result set checksums of the retrieved and provided query. Over time the result set might have changed. That is why we compare the result sets with their respective timestamps so we can see whether changes like number of rows returned or value changes occured. Also the order of rows might differ, if no sort operation is aplied, simply due to the fetching mechanism of the underlying database management system. The sort operation we used before should make the rows of either dataset unambiguos. If the **new query still yields the same result set checksum** then we can simply retrieve and return the already existing citation snippet of the stored query. If either of these two checks are not fullfilled, meaning that the query is truly new, a new query PID gets created followed by a citation snippet. Both information along with other query attributes get encapsulated within a query object and written to the query store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A user retrieves data via an user interface by either executing a query or using graphical features to build the data set (which, in fact, executes a query in the background). At any point the user can request the citation text by means of graphical features (e.g. button) or terminal commands. Following example shall demonstrate the citation process as illustrated in figure 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: Query is new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryUtils = QueryData(original_query, timestamp1, prefixes)\n",
    "\n",
    "print(queryUtils.sparql_prefixes)\n",
    "print(queryUtils.query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R4a - Query uniqueness: Normalize query algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Number | Statement description | Normalization measure   |\n",
    "|------|------|------|\n",
    "|1 | WHERE clause is optional | A where clause will always be inserted |\n",
    "|2 | \"rdf:type\" predicate can be replaced by \"a\" | rdf:type will always be replaced by \"a\" |\n",
    "|3 | if all variables are selected one does not need to write a variable in the form ?s but can just use an asterisk | Variables will always be explicitely mentioned and ordered alphabetically |\n",
    "|4 | If the same subject is used multiple times in subsequent triplets separated by a dot it can be simplified by writing just the first subject variable name, separating the triplets by semicolons and leaving out the other variable names that are equal to the one in the first triplet | Triples will never be simplified and simplified triples will be made explicit |\n",
    "|5 |   The order of triple statements does not affect the outcome | Triple statements will be ordered alphabetically by subject, predicate, object |\n",
    "|6 | Aliases via BIND keyword just rename variables but the query result stays the same  | Do not know how to tackle yet |\n",
    "|7 | Variable names in general can differ between two queries without changing the outcome.  | Variables will be replaced by letters from the alphabet. For each variable a letter from the alphabet will be assigned starting with 'a' and in chronological order. Two letters will be used and chronological combinations will be assigned should there be more than 26 variables.  |\n",
    "|8 | Finding variables that are not bound can be written in two ways: 1. with optional keyword adding the optional triplet combined with filter condition !bound(?var); 2. with \"filter not exists (triplet)\" | No solution yet |\n",
    "|9 | Inverting the order of the triplet (object predicate subject instead of subject predicate object) using \"^\" gives the same results | Inverted triples will be back-inverted and \"^\" will thereby be removed |\n",
    "|10 | sequence paths can reduce the number of triplets in the query statement and are commonly used. | Sequence paths will be made explicit in form triple statements |\n",
    "|11 | Prefixes can be interchanged in the prefix section before the query and subsequently in the query without changing the outcome. | All prefixes will be substituted with their underlying URIs |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the normalization step on our example query which covers RDF statements from the table above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_query_tree = queryUtils.normalize_query_tree(original_query, prefixes)\n",
    "print(normalized_query_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proof of concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To proof that normalized query objects of semantically identical queries yield the same checksums a bunch of semantically identical queries with respect to aforementioned semantics are prepared. Then the queries are normalized by normalizing their individual \"algebra trees\" and their checksums are computed. We can see that all checksums are equal, which is the expected result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = {'citing': 'http://ontology.ontotext.com/citing/',\n",
    "            'pub': 'http://ontology.ontotext.com/taxonomy/',\n",
    "            'xsd': 'http://www.w3.org/2001/XMLSchema#',\n",
    "            'publishing': 'http://ontology.ontotext.com/publishing#'}\n",
    "\n",
    "#1: WHERE clause is optional\n",
    "query_1 = \"\"\"\n",
    "select ?document ?mention ?party ?person ?personLabel ?value {\n",
    "    ?mention publishing:hasInstance ?person .\n",
    "    ?document publishing:containsMention ?mention . \n",
    "    ?person pub:memberOfPoliticalParty ?party .\n",
    "    ?person pub:preferredLabel ?personLabel .\n",
    "    ?party pub:hasValue ?value .\n",
    "    ?value pub:preferredLabel \"Democratic Party\"@en .\n",
    "    filter(?personLabel = \"Judy Chu\"@en)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "#3: if all variables are selected one does not need to write a \n",
    "# variable in the form ?s but can just use an asterisk\n",
    "query_3 = \"\"\"\n",
    "select * {\n",
    "    ?mention publishing:hasInstance ?person .\n",
    "    ?document publishing:containsMention ?mention . \n",
    "    ?person pub:memberOfPoliticalParty ?party .\n",
    "    ?person pub:preferredLabel ?personLabel .\n",
    "    ?party pub:hasValue ?value .\n",
    "    ?value pub:preferredLabel \"Democratic Party\"@en .\n",
    "    filter(?personLabel = \"Judy Chu\"@en)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "#5: The order of triple statements does not affect the outcome\n",
    "query_5 = \"\"\"\n",
    "select ?document ?mention ?party ?person ?personLabel ?value {\n",
    "    ?document publishing:containsMention ?mention . \n",
    "    ?person pub:memberOfPoliticalParty ?party .\n",
    "    ?person pub:preferredLabel ?personLabel .\n",
    "    ?mention publishing:hasInstance ?person .\n",
    "    ?party pub:hasValue ?value .\n",
    "    ?value pub:preferredLabel \"Democratic Party\"@en .\n",
    "    filter(?personLabel = \"Judy Chu\"@en)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "#7: Variable names in general can differ between two queries without changing the outcome\n",
    "query_7 = \"\"\"\n",
    "select ?mention ?x ?party ?person ?personLabel ?value {\n",
    "    ?x publishing:containsMention ?mention . \n",
    "    ?person pub:memberOfPoliticalParty ?party .\n",
    "    ?person pub:preferredLabel ?personLabel .\n",
    "    ?mention publishing:hasInstance ?person .\n",
    "    ?party pub:hasValue ?value .\n",
    "    ?value pub:preferredLabel \"Democratic Party\"@en .\n",
    "    filter(?personLabel = \"Judy Chu\"@en)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "queries = {\"query1\": query_1, \n",
    "           \"query3\": query_3,\n",
    "           \"query5\": query_5, \n",
    "           \"query7\": query_7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def query_checksum_workflow(query_string, query_name, prefixes, timestamp):\n",
    "    q_utils = QueryData(query_string, timestamp, prefixes)\n",
    "    normalized_query_tree = q_utils.normalize_query_tree(query_string, prefixes) \n",
    "    query_checksum = q_utils.compute_checksum(normalized_query_tree) \n",
    "    print(\"{0}: \\t checksum {1} \".format(query_name, query_checksum))\n",
    "\n",
    "for query_name, query_string in queries.items():\n",
    "    query_checksum_workflow(query_string, query_name, prefixes, timestamp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the checksums are all equal meaning that the normalization behaves as intended and the query algebra is indeed the same for all of the above query syntaxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R4b - Query uniqueness: Compute query checksum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The checksum of the normalized query string is computed. However, the query is not timestamped yet. We want first to check whether a normalized query with the same checksum exists. If so, we will only then apply the timestamp and furthermore sort operation. As our query is new at this point the checksum will not be found. We will move on to generate the citation snippet and store the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_checksum = queryUtils.compute_checksum(normalized_query_tree)\n",
    "print(query_checksum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R7 - Query Timestamping\n",
    "Extend query with the timestamp as of citing. if the timestamp was already assigned to the query object the function below will use this member variable to the extend the query string. Therefore, no timestamps needs to be passed. If, however, a timestamp is passed, it will be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'queryUtils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a7fba448e7a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Parameters are: self.citation_timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtimestamped_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueryUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorate_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefixes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'queryUtils' is not defined"
     ]
    }
   ],
   "source": [
    "# Parameters are: self.citation_timestamp\n",
    "timestamped_query = queryUtils.decorate_query(original_query, prefixes, timestamp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proof of concept\n",
    "\n",
    "We can see the versioning extensions highlighted. The first one is the citation timestamp in blue. For every triple statement in the query two nested triple statements with the valid_from and valid_until date and a filter to select only the triples as of citation date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for presentation\n",
    "timestamped_query_colored = queryUtils.decorate_query(original_query, prefixes, timestamp1, colored=True)\n",
    "print(timestamped_query_colored)\n",
    "\n",
    "# SPARQL extensions: Functions can be added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R5 - Stable Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge with sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R5 recommendation states that there must be a \"unique criterion, which allows creating a total ordering of the records in the data set and the subsets thereof\". \"Automatically specifying the primary key, followed by a user sort\" is proposed as solution. The challenge especially for RDF datasets is that there are no primary keys. It could be up for discussion whether such constraints could be placed in the metamodel or triples could be annotated by the RDF database designer. Let us for now assume the probably more realistic case that each subgraph needs to be thought of as an individual dataset without any constraints on the result columns. Therefore, a unique index that can be used for sorting prior to the user sorts needs to be derived first. \n",
    "\n",
    "We tried to tackle this problem with an algorithm that computes the \"simplest\" possible unique (multi-)index from the dataset. Simple hereby means that each (multi-)index is a minimum set of columns. E.g. only one column could be enough to serve as a unique index for sorting. This unique index does not have to be the natural or business key which the user would define based on the business model. The algorithm starts by iterating through every single column and checking whether it would make up a unique index or not. If no unique index is found it goes on by trying out every column pair combination. If still no unique indexes are found it goes on with triple combinations and so on. Bear in mind that the iteration is deterministic and depends on the column order (see discussion later on). One challenge we face with the index derivation is that there could be more possible solutions derived. E.g. there could be two columns where each has as many distinct values as rows or two possible compositions of columns where each composition would yield an unambiguos order upon every execution when used in the \"order by\" clause. If such a list of multiple possible multi-indexes is returned by the algorithm a solution would be to always take the first index from that list. This ultimately leads to the discussion whether the column names/aliases and column order should matter in the select clause of the query, thus, whether two queries should be called semantically identical even if they use different column aliases and/or columns are placed in a differing order. Let us start with distinguishing four possible cases where we could call two queries semantically identical.\n",
    "\n",
    "a = Two queries have the same column aliases in the select clause;\n",
    "b = Two queries have the same column order in the select clause\n",
    "\n",
    "* Case 1: a $\\wedge$ b: This case is trivial as both queries are syntactically identical. $\\newline$\n",
    "\n",
    "* Case 2: a $\\wedge$ $\\neg$ b: From a business perspective it could make sense to consider such queries as \"one and the same\". After the dataset is obtained the column placement could be rearranged anyway just for presentation reasons without hazarding the further processing by any means. Let us now assume that we are given **two** SPARQL queries with different column placements but otherwise identical. The natural or business key for both queries is unknown, as already stated, and we need to make a suggestion on which index to use for sorting. The currently developed algorithm could ensure that for such two queries two identically ordered lists are returned only if a sort is done on the column names.  $\\newline$\n",
    "\n",
    "* Case 3: $\\neg$ a $\\wedge$ b: It is easy to imagine that in business setting one wants to have a controlled set of domain values to foster understanding of business terms. One business term could have multiple synonyms or abbreviations, e.g. one dataset could have a column name \"track\" and the other one \"song\" but they mean the same thing. So it is reasonable that queries with different names could be considered semantically identical. Let us make the same assumptions as in case 2. Our algorithm could ensure that for such queries the same output is produced by normalizing the column names first, meaning that a letter or a number is assigned to each column so that the datasets end up having identical column names. However, this would mean that we are not allowed to sort the columns prior to normalization as the mapping to letters or numbers would differ betweem these two sets. This finally leads to our final \"impossible\" case.\n",
    "\n",
    "* Case 4: $\\neg$ a $\\wedge$ $\\neg$ b: If both conditions are not met but the two queries are still considered as semantically identical our algorithm has no chance to produce identically ordered lists of multi-indexes. This raises the question whether we either need to look for another algorithm to determine unqiue indexes for sorting or of we should ask for user input at first place to define a natural key for the dataset he/she is about to cite.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalized and timestamped query is now extended with the \"order by\" operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should different column names produce different query checksums?\n",
    "query_result = rdf_engine.get_data(timestamped_query, prefixes)\n",
    "rdf_ds = RDFDataSetData(query_result)\n",
    "sort_variables = rdf_ds.sort_order\n",
    "query_for_execution = queryUtils.decorate_query(original_query, prefixes, timestamp1, sort_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proof of concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different evaluation scenarios\n",
    "test_df = pd.read_csv(\"Playground/test_primary_key_suggestor_ds1.csv\", delimiter=',')\n",
    "rdf_ds = RDFDataSetData(test_df)\n",
    "rdf_ds.sort_order = rdf_ds.create_sort_index()\n",
    "print(\"Test 1: Three equal columns and one different. One row is duplicated therefore it does not matter which one comes first\") \n",
    "print(test_df)\n",
    "print(\"Suggested (composite) primary key(s)\", rdf_ds.sort_order)\n",
    "print()\n",
    "\n",
    "test_df = pd.read_csv(\"Playground/test_primary_key_suggestor_ds2.csv\", delimiter=',')\n",
    "rdf_ds.dataset = test_df\n",
    "rdf_ds.sort_order = rdf_ds.create_sort_index()\n",
    "print(\"test 2: Multiple possible composite keys. Is user feedback needed here?\") \n",
    "print(test_df)\n",
    "print(\"Suggested (composite) primary key(s)\", rdf_ds.sort_order)\n",
    "print()\n",
    "\n",
    "test_df = pd.read_csv(\"Playground/test_primary_key_suggestor_ds3.csv\", delimiter=',')\n",
    "rdf_ds.dataset = test_df\n",
    "rdf_ds.sort_order = rdf_ds.create_sort_index()\n",
    "print(\"test 3: Column names changed compared to test 2 so that a sort of column \" \\\n",
    "      \"names would yield a different order for datasets in test 2 and test 3. However, the output compared\" \\\n",
    "      \" to test 2 does not change. For RDF-data this might be desired as variable names/labels do not matter\")\n",
    "print(test_df)\n",
    "print(\"Suggested (composite) primary key(s)\", rdf_ds.sort_order)\n",
    "print()\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(\"Playground/test_primary_key_suggestor_ds4.csv\", delimiter=',')\n",
    "rdf_ds.dataset = test_df\n",
    "rdf_ds.sort_order = rdf_ds.create_sort_index()\n",
    "print(\"test 4: Like test 3 but different permutation of columns. This, in fact, yields a different order \"\\\n",
    "      \"of key attributes within each suggested composite key, thus also leading to a differnt sorting. \"\\\n",
    "      \"If this gets 'fixed' then test 3 fails. Is user input needed here?\") \n",
    "print(test_df)\n",
    "print(\"Suggested (composite) primary key(s)\", rdf_ds.sort_order)\n",
    "\n",
    "# Test 5: Test 3 + Column names are permuted + suggested keys have different number of\n",
    "# distinct stacked key attributes values\n",
    "# Output: Same key suggestions as for test 4\n",
    "test_df = pd.read_csv(\"Playground/test_primary_key_suggestor_ds5.csv\", delimiter=',')\n",
    "rdf_ds.dataset = test_df\n",
    "rdf_ds.sort_order = rdf_ds.create_sort_index()\n",
    "print(\"test 5: Like test 4 but all columns are have different number of distinct values now. The composite key(s) \"\\\n",
    "      \"with the lowest sum of 'distinct stacked key attribute values' from the list of potential \" \\\n",
    "      \"composite keys gets suggested\") \n",
    "print(test_df)\n",
    "print(\"Suggested (composite) primary key(s)\", rdf_ds.sort_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with real data from the new dataset\n",
    "test_df = pd.read_csv(\"Playground/dem_and_rep_party_members_mentions.csv\", delimiter=',')\n",
    "rdf_ds = RDFDataSetData(test_df)\n",
    "rdf_ds.sort_order = rdf_ds.create_sort_index()\n",
    "print(test_df)\n",
    "print(rdf_ds.sort_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for presentation\n",
    "query_for_execution_colored = queryUtils.decorate_query(original_query, prefixes, timestamp1,\n",
    "                                                        sort_variables, colored=True)\n",
    "print(query_for_execution_colored) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R6 - Compute Result set checksum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The checksum computation is column order independent but row order dependent. The row order indenpendence is accomplished by taking row vector sums. Trivialy, the order of the summands does not affect the sum. The rows are sorted by a unique index before the checksum is computed. The index is either computed by our algorithm or provided by the user if the algorithm yields ambiguous results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = rdf_engine.get_data(timestamped_query, prefixes)\n",
    "\n",
    "query_tree_variables = []\n",
    "for v in queryUtils.variables:\n",
    "    if isinstance(v, Variable):\n",
    "        query_tree_variables.append(v.n3()[1:])\n",
    "\n",
    "dataset_variables = _intersection(query_result.columns, query_tree_variables)\n",
    "rdf_ds = RDFDataSetData(query_result[dataset_variables])\n",
    "sorted_ds = rdf_ds.sort()\n",
    "rdf_ds.dataset = sorted_ds\n",
    "rdf_ds.checksum = rdf_ds.compute_checksum()\n",
    "\n",
    "print(\"Result set checksum: \", rdf_ds.checksum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proof of concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **R4a - Query uniqueness: Normalize query algebra** we defined some queries to proof that they are semantically identical by computing and comparing their checksums. Now we can further support the proof by showing that the result set checksums are also equal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workflow_result_set_checksum(query_string, query_name, prefixes, timestamp):\n",
    "    queryUtils = QueryData(query_string, timestamp, prefixes)\n",
    "    timestamped_query = queryUtils.decorate_query()\n",
    "    query_result = rdf_engine.get_data(timestamped_query, prefixes)\n",
    "    \n",
    "    query_tree_variables = []\n",
    "    for v in queryUtils.variables:\n",
    "        if isinstance(v, Variable):\n",
    "            query_tree_variables.append(v.n3()[1:])\n",
    "    \n",
    "    dataset_variables = _intersection(query_result.columns, query_tree_variables)\n",
    "    rdf_ds = RDFDataSetData(query_result[dataset_variables])\n",
    "    #custom_sort_order = ('mention', )\n",
    "    # custom_sort_order can be provided as parameter in sort()\n",
    "    sorted_ds = rdf_ds.sort()\n",
    "    rdf_ds.dataset = sorted_ds\n",
    "    rdf_ds.checksum = rdf_ds.compute_checksum()\n",
    "    \n",
    "    print(\"query {0}: \\t sort_order: {1} \\t result_set_checksum: {2}\".format(query_name,\n",
    "                                                                             rdf_ds.sort_order,\n",
    "                                                                             rdf_ds.checksum))\n",
    "\n",
    "for query_name, query_string in queries.items():\n",
    "    workflow_result_set_checksum(query_string, query_name, prefixes, timestamp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at two citations dates that are one day apart and we know that the dataset has not changed between these two dates, we would expect the same result set checksum. As shown below, this is exactly what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp1 was already assigned above, just here for reminder\n",
    "# timestamp1 = datetime(2020, 9, 8, 12, 11, 21, 941000, vieTZObject) \n",
    "timestamp4 = datetime(2020, 9, 9, 12, 11, 21, 941000, vieTZObject)\n",
    "\n",
    "workflow_result_set_checksum(original_query, \"original query\", prefixes, timestamp1)\n",
    "workflow_result_set_checksum(original_query, \"original query\", prefixes, timestamp4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R10 - Automated Citation texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the citation snippet some information is needed first. First, we need to generate a query PID which is based on the citation timestamp and the query checksum. This way we will be able to identify queries across a timeframe where multiple citations could occur where the result set changes but the query stays unchanged, latter meaning that the checksum is the same. Second, we need to describe our result set. Unfortunatelly, we do not have means yet to automatically derive a description from the underlying result set. That is why we will manually provide it at this stage of project. Last, we need to collect metadata about the cited dataset, such as author, publisher, resource type, title, edition. These metadata attributes are inspired by existing metadata sets, such as *Dublin core*, *dataverse* and *FORCE11*. At this point, we will pass a manually created metadata set, which would usually be collected from the landing page or environment where the citation framework is employed. Other suggested metadata attributes, such as unique number fingerprint (result set checksum), persistent URI (query checksum) will be generated by the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resource type \"Dataset\" is taken from the controlled list of values. The value \"RDF data\" is arbitrary\n",
    "citation_data = CitationData(identifier=\"DOI_to_landing_page\", creator=\"Filip Kovacevic\",\n",
    "                             title=\"Judy Chu occurences\", publisher=\"Filip Kovacevic\",\n",
    "                             publication_year=\"2021\", resource_type=\"Dataset/RDF data\", \n",
    "                             other_citation_data={\"Contributor\": \"Tomasz Miksa\"})\n",
    "\n",
    "\n",
    "# Generate citation snippet\n",
    "queryUtils.generate_query_pid(queryUtils.checksum, timestamp1)\n",
    "citation_snippet = generate_citation_snippet(queryUtils.pid, citation_data)\n",
    "citation_data.citation_snippet = citation_snippet\n",
    "print(citation_snippet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R9 - Store query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that is left to do is to store the query and all the relevant information that can be read from the query object along with the citation snippet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_ds.description = \"Result set description: All documents where Judy Chu was mentioned with every mention listed\"\n",
    "\n",
    "query_store = qs.QueryStore(relative_path_to_db=\"API/persistence/query_store.db\")\n",
    "query_store.store(queryUtils, rdf_ds, citation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: Query exists and result set still the same as last time it was cited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute Query\n",
    "The same citation snippet that was generated in Case 1 should get returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_query_data, existing_query_rdf_ds_data, existing_query_citation_data = query_store.lookup(queryUtils.checksum)\n",
    "if existing_query_data:\n",
    "    if rdf_ds.checksum == existing_query_rdf_ds_data.checksum:\n",
    "        query_pid = existing_query_data.pid\n",
    "    else:\n",
    "        # Case 3\n",
    "        pass \n",
    "    citation_snippet = citation_data.citation_snippet\n",
    "else:\n",
    "    # Case 1\n",
    "    pass \n",
    "\n",
    "print(citation_snippet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3: Query exists and the result set changed compared to last time it was cited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create a new query \"query2\" where the query string is the same as our example query but the citation timestamp is a more recent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = QueryData(original_query, timestamp2, prefixes)\n",
    "\n",
    "# Same query checksums\n",
    "print(queryUtils.checksum)\n",
    "print(query2.checksum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will repeat the procedure as done when citing the query for the first time (normalization, timestamping, sorting, checksum computation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_query_tree2 = query2.normalize_query_tree()\n",
    "query2_checksum = query2.compute_checksum(normalized_query_tree2)\n",
    "# Timestamp 1 < timestamp 2\n",
    "timestamped_query2 = query2.decorate_query(original_query, prefixes, timestamp2) \n",
    "query2_result = rdf_engine.get_data(timestamped_query2, prefixes)\n",
    "\n",
    "query2_tree_variables = []\n",
    "for v in query2.variables:\n",
    "    if isinstance(v, Variable):\n",
    "        query2_tree_variables.append(v.n3()[1:])\n",
    "\n",
    "dataset2_variables = _intersection(query2_result.columns, query2_tree_variables)\n",
    "rdf_ds2 = RDFDataSetData(query2_result[dataset_variables])\n",
    "sorted_ds2 = rdf_ds2.sort()\n",
    "rdf_ds2.dataset = sorted_ds2\n",
    "rdf_ds2.checksum = rdf_ds2.compute_checksum()\n",
    "\n",
    "print(\"Different result set checksums because as of timestamp2 there is one record less in the dataset\")\n",
    "print(rdf_ds.dataset.count(), rdf_ds.checksum)\n",
    "print(rdf_ds2.dataset.count(), rdf_ds2.checksum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we need to cover the third case meaning that we will lookup the query and find a match in the query store. We will compare the result set checksums of the existing and new query and realize that the checksums are not matching. Therefore, a new query PID and citation snippet will be generated and stored. From the printed citation snippet we can see that a new query PID had been assigned. To make the experiment repeatable we remove all the records we have inserted so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Citation Data creation\n",
    "citation_data2 = CitationData(identifier=\"DOI_to_landing_page\", creator=\"Filip Kovacevic\",\n",
    "                                title= \"Judy Chu occurences\", publisher=\"Max Musterman\",\n",
    "                                publication_year=\"2021\", resource_type=\"Dataset/RDF data\", \n",
    "                                other_citation_data={\"Contributor\": \"Tomasz Miksa\"})\n",
    "\n",
    "# Algorithm\n",
    "existing_query2_data, existing_query2_rdf_ds_data, existing_query2_citation_data = query_store.lookup(query2.checksum)\n",
    "if existing_query2_data:\n",
    "    print(\"Query 2 result set checksum: {0}\".format(rdf_ds2.checksum))\n",
    "    print(\"Existing query result set checksum: {0}\".format(existing_query2_rdf_ds_data.checksum))\n",
    "    print(\"\\n\")\n",
    "    if rdf_ds2.checksum == existing_query2_rdf_ds_data.checksum:\n",
    "        # Case 2\n",
    "        pass \n",
    "    else:\n",
    "        query2.generate_query_pid(query2.checksum, timestamp2)\n",
    "        citation_snippet2 = generate_citation_snippet(query2.pid, citation_data2)\n",
    "        citation_data2.citation_snippet = citation_snippet2\n",
    "        query_store.store(query2, rdf_ds2, citation_data2, False)\n",
    "        # new Query PID\n",
    "        query_pid2 = query2.pid \n",
    "    citation_snippet2 = citation_data2.citation_snippet\n",
    "else:\n",
    "    # Case 1\n",
    "    pass \n",
    "\n",
    "print(\"\\nNew citation snippet: \")\n",
    "print(citation_snippet2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the experiment to be repeatable every time this notebook is run we need to make sure that records which were previously inserted are removed from the query store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_store._remove(queryUtils.checksum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolving PIDs and Retrieving the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data set using the Query PID\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
